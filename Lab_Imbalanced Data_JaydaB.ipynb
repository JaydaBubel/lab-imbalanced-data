{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7efce124",
   "metadata": {},
   "source": [
    "# 1./2. Load the dataset and explore the variables; try to predict variable Churn using a logistic regression on variables tenure, SeniorCitizen, MonthlyCharges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "a5928a34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: imblearn in ./anaconda3/lib/python3.10/site-packages (0.0)\n",
      "Requirement already satisfied: imbalanced-learn in ./anaconda3/lib/python3.10/site-packages (from imblearn) (0.10.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in ./anaconda3/lib/python3.10/site-packages (from imbalanced-learn->imblearn) (2.2.0)\n",
      "Requirement already satisfied: scipy>=1.3.2 in ./anaconda3/lib/python3.10/site-packages (from imbalanced-learn->imblearn) (1.10.0)\n",
      "Requirement already satisfied: numpy>=1.17.3 in ./anaconda3/lib/python3.10/site-packages (from imbalanced-learn->imblearn) (1.23.5)\n",
      "Requirement already satisfied: joblib>=1.1.1 in ./anaconda3/lib/python3.10/site-packages (from imbalanced-learn->imblearn) (1.1.1)\n",
      "Requirement already satisfied: scikit-learn>=1.0.2 in ./anaconda3/lib/python3.10/site-packages (from imbalanced-learn->imblearn) (1.2.1)\n",
      "········\n"
     ]
    }
   ],
   "source": [
    "!pip install imblearn\n",
    "import imblearn\n",
    "import pymysql\n",
    "from sqlalchemy import create_engine\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import getpass\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import Normalizer, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "password = getpass.getpass()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "8e3a58de",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# make the connection with the database\n",
    "connection_string = 'mysql+pymysql://root:' + password + '@localhost/customer_churn'\n",
    "engine = create_engine(connection_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e43145c",
   "metadata": {},
   "source": [
    "# 3. Extract the target variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "9692af0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        No\n",
      "1        No\n",
      "2       Yes\n",
      "3        No\n",
      "4       Yes\n",
      "       ... \n",
      "7027     No\n",
      "7028     No\n",
      "7029     No\n",
      "7030    Yes\n",
      "7031     No\n",
      "Name: Churn, Length: 7032, dtype: object\n"
     ]
    }
   ],
   "source": [
    "query = '''\n",
    "        SELECT Churn\n",
    "        FROM customer_churn\n",
    "        '''\n",
    "churn_data = pd.read_sql_query(query, engine) # create query\n",
    "\n",
    "targ_variable = churn_data['Churn'] # extract and print targ variable\n",
    "print(targ_variable)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9089a98d",
   "metadata": {},
   "source": [
    "# 4. Extract the independent variables and scale"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b45b71fa",
   "metadata": {},
   "source": [
    ">Extract other 3 variables along with Churn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "5415f5a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tenure</th>\n",
       "      <th>SeniorCitizen</th>\n",
       "      <th>MonthlyCharges</th>\n",
       "      <th>Churn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>29.85</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>56.95</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>53.85</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "      <td>42.30</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>70.70</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   tenure  SeniorCitizen  MonthlyCharges Churn\n",
       "0       1              0           29.85    No\n",
       "1      34              0           56.95    No\n",
       "2       2              0           53.85   Yes\n",
       "3      45              0           42.30    No\n",
       "4       2              0           70.70   Yes"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_sql_query('SELECT * FROM customer_churn', engine)\n",
    "query = '''\n",
    "        SELECT tenure, SeniorCitizen, MonthlyCharges, Churn\n",
    "        FROM customer_churn\n",
    "        '''\n",
    "data = pd.read_sql_query(query, engine)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "a6bad50f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tenure              int64\n",
       "SeniorCitizen       int64\n",
       "MonthlyCharges    float64\n",
       "Churn              object\n",
       "dtype: object"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dtypes # unsure whether to leave Churn as categorical or not... will leave for now."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa7eeca8",
   "metadata": {},
   "source": [
    ">Use scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "a6e9a27f",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X = pd.get_dummies(data.drop('Churn', axis=1))\n",
    "y = data['Churn']\n",
    "X_scaled = scaler.fit_transform(X)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52e87c5b",
   "metadata": {},
   "source": [
    "# 5. Build the logistic regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "0072b831",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.783226723525231\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.82      0.91      0.86      1033\n",
      "         Yes       0.63      0.44      0.52       374\n",
      "\n",
      "    accuracy                           0.78      1407\n",
      "   macro avg       0.72      0.67      0.69      1407\n",
      "weighted avg       0.77      0.78      0.77      1407\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "model = LogisticRegression()\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "predictions = classification.predict(X_test)\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72a4a51a",
   "metadata": {},
   "source": [
    "# 6. Evaluate the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "c68de500",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.783226723525231\n",
      "Precision: 0.6292134831460674\n",
      "Recall: 0.44919786096256686\n",
      "F1-score: 0.5241809672386896\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Calculate evaluation metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, pos_label='Yes')\n",
    "recall = recall_score(y_test, y_pred, pos_label='Yes')\n",
    "f1 = f1_score(y_test, y_pred, pos_label='Yes')\n",
    "\n",
    "# Print the evaluation metrics\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1-score:\", f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "47f6ccea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy: model has accuracy of 78.32%; this amount of predictions made by model were correct.\n",
    "# precision: when the model predicts a customer will churn, it is right only 62.92% of the time.\n",
    "# recall: proportion of positive cases (churn) that were correctly predicted by model; not so good\n",
    "# F1: mean of precision/recall; not sure if this is decent or not"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bc94bec",
   "metadata": {},
   "source": [
    "# 7. Even a simple model will give us more than 70% accuracy. Why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "d76343b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perhaps data imbalance: when the categories are unbalanced and the number of them arent equal/similar, then a model can still have high accuracy by predicting the majority class most of the time, since it's better represented in the data set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c09ad29",
   "metadata": {},
   "source": [
    "# 8. Synthetic Minority Oversampling TEchnique (SMOTE) is an over sampling technique based on nearest neighbors that adds new points between existing points. Apply imblearn.over_sampling.SMOTE to the dataset. Build and evaluate the logistic regression model. Is it there any improvement?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16d64691",
   "metadata": {},
   "source": [
    ">Apply Smote to the data set, see values before and after"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "b4f2c317",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BeforeSMOTE:\n",
      "No     5163\n",
      "Yes    1869\n",
      "Name: Churn, dtype: int64\n",
      "AfterSMOTE:\n",
      "No     5163\n",
      "Yes    5163\n",
      "Name: Churn, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "smote = SMOTE() \n",
    "X_resampled, y_resampled = smote.fit_resample(data.drop('Churn', axis=1), data['Churn'])\n",
    "\n",
    "# Value counts before\n",
    "print(\"BeforeSMOTE:\")\n",
    "print(y.value_counts())\n",
    "\n",
    "# Value counts after\n",
    "print(\"AfterSMOTE:\")\n",
    "print(pd.Series(y_resampled).value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "831c4a5a",
   "metadata": {},
   "source": [
    ">Repeat the logisic regression model and comment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "1fcf8281",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7270087124878993\n",
      "Precision: 0.7255092143549952\n",
      "Recall: 0.7269193391642371\n",
      "F1-score: 0.7262135922330096\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42)\n",
    "\n",
    "# Build the logistic regression model\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate evaluation metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, pos_label='Yes')\n",
    "recall = recall_score(y_test, y_pred, pos_label='Yes')\n",
    "f1 = f1_score(y_test, y_pred, pos_label='Yes')\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1-score:\", f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "f112d5dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy has slightly declined, but all other scores have improved. The recall score has significantly imoproved."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "661ff1fc",
   "metadata": {},
   "source": [
    "# 9. Tomek links are pairs of very close instances, but of opposite classes. Removing the instances of the majority class of each pair increases the space between the two classes, facilitating the classification process. Apply imblearn.under_sampling.TomekLinks to the dataset. Build and evaluate the logistic regression model. Is it there any improvement?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae2db352",
   "metadata": {},
   "source": [
    ">Apply Tomeklinks to the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "10a3700b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No     4701\n",
      "Yes    1869\n",
      "Name: Churn, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from imblearn.under_sampling import TomekLinks\n",
    "\n",
    "X = data.drop('Churn', axis=1)\n",
    "y = data['Churn']\n",
    "\n",
    "tomek_links = TomekLinks()\n",
    "X_resampled, y_resampled = tomek_links.fit_resample(X, y)\n",
    "\n",
    "# Check the class distribution after undersampling\n",
    "print(y_resampled.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eebb7c04",
   "metadata": {},
   "source": [
    "> Run again the logistic regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "3a079659",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7732115677321156\n",
      "Precision: 0.6291390728476821\n",
      "Recall: 0.5053191489361702\n",
      "F1-score: 0.56047197640118\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42)\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, pos_label='Yes')\n",
    "recall = recall_score(y_test, y_pred, pos_label='Yes')\n",
    "f1 = f1_score(y_test, y_pred, pos_label='Yes')\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1-score:\", f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f2c3a69",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
